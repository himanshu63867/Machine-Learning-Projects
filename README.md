# üöÄ Machine Learning Projects

This repository contains end-to-end machine learning projects I built using Python and Jupyter Notebook.  
Each project covers **data preprocessing, model building, evaluation, and insights**.

---

## üìå Projects

### 1. üì∞ Fake News Prediction
**Goal:** Classify news articles as real or fake using Natural Language Processing (NLP).  

- **Data Preprocessing:** Tokenization, stopword removal, TF-IDF vectorization.  
- **Models:** Logistic Regression, Naive Bayes, Random Forest.  
- **Evaluation:** Accuracy, Precision, Recall, F1-score.  
- **Result:** Achieved **XX% accuracy** with Logistic Regression (best performing model).  

üîß **Tools & Libraries:** Python, Scikit-learn, NLTK, Pandas, Matplotlib  

---

### 2. ü•ó Food Nutrition Analysis
**Goal:** Analyze nutritional values of food items and predict/calibrate categories.  

- **EDA:** Visualized nutrient distributions (calories, fat, protein, carbs).  
- **Modeling:** Classification models applied to food categories.  
- **Feature Importance:** Identified most influential nutrients.  
- **Result:** Model achieved **XX% accuracy** in predicting food groups.  

üîß **Tools & Libraries:** Python, Pandas, Matplotlib, Seaborn, Scikit-learn  

---

### 3. ‚õèÔ∏è Rock vs Mine Prediction (Sonar Dataset)
**Goal:** Classify sonar signals as **rock** or **mine** (geophysical exploration).  

- **Data Preprocessing:** Normalized dataset, handled noisy values.  
- **EDA:** Statistical summaries & visualizations.  
- **Models:** Logistic Regression, k-NN, Decision Trees, Random Forest.  
- **Evaluation:** Accuracy, Precision, Recall, F1-score.  
- **Result:** Achieved **XX% accuracy** with Random Forest (best model).  

üîß **Tools & Libraries:** Python, Scikit-learn, Pandas, Seaborn, Matplotlib  

---

### 4. üí≥ Credit Card Fraud Detection
**Goal:** Detect fraudulent transactions in an imbalanced dataset.  

- **Data Preprocessing:** Handled class imbalance using **SMOTE (Synthetic Minority Oversampling Technique)** and under-sampling.  
- **EDA:** Analyzed transaction patterns and correlations between features.  
- **Models:** Logistic Regression, Random Forest, XGBoost, LightGBM, CatBoost.  
- **Evaluation:** Focused on **Precision, Recall, F1-score, and ROC-AUC** (since accuracy is misleading in imbalanced data).  
- **Result:** Best model (XGBoost/LightGBM) achieved **XX% ROC-AUC** and reduced false negatives significantly.  

üîß **Tools & Libraries:** Python, Scikit-learn, Imbalanced-learn (SMOTE), XGBoost, LightGBM, CatBoost, Pandas, Matplotlib, Seaborn  

---

<--- Key Skills Demonstrated -->
- Data Cleaning & Preprocessing  
- Exploratory Data Analysis (EDA)  
- Classification Models (Logistic Regression, Decision Trees, Random Forest, Gradient Boosting)  
- Handling Imbalanced Data (SMOTE, Under-sampling, Class weights)  
- Model Evaluation (Accuracy, Precision, Recall, F1-score, ROC-AUC)  
- Feature Importance & Explainability  
- Data Visualization  

---

## üõ†Ô∏è Tech Stack
- **Language:** Python  
- **Libraries:** Scikit-learn, Pandas, NumPy, Matplotlib, Seaborn, NLTK, XGBoost, LightGBM, CatBoost, Imbalanced-learn  
- **Environment:** Jupyter Notebook, Google Colab  

---

‚ú® Through these projects, I gained hands-on experience in applying machine learning techniques to **real-world problems**, ranging from text classification and nutrition analysis to fraud detection and geophysical exploration.


